ğŸ“˜ SafeNet

Text + Image Moderation System
Version: MVP Prototype

ğŸ“Œ Overview

SafeNet is an MVP prototype designed to detect cyberbullying, toxic language, and harmful content in both text and images.
The project demonstrates the core ideas of an automated moderation system:

âœ” how a moderation API works
âœ” how text and image analysis can be implemented
âœ” how a dashboard for moderators may look
âœ” how content flows through a backend + frontend system

SafeNet includes:

FastAPI backend

Text analysis module (rule-based)

Image analysis module (OCR + text detection)

Moderator Dashboard built with Streamlit

Dockerized architecture (Docker Compose)

This MVP focuses on demonstrating functionality, not fully accurate ML performance.

```
/safenet-api
    â”œâ”€â”€ main.py                 
    â”œâ”€â”€ text_analyzer.py        
    â”œâ”€â”€ ocr_analyzer.py         
    â”œâ”€â”€ requirements.txt
    â””â”€â”€ Dockerfile

/safenet-dashboard
    â”œâ”€â”€ Dashboard_app.py        
    â”œâ”€â”€ requirements.txt
    â””â”€â”€ Dockerfile

docker-compose.yml
README.md
```

ğŸ³ Running via Docker

```
docker compose up --build
```

2. Access the running services:
Service	URL
Backend API (FastAPI)	http://localhost:8000
Moderation Dashboard http://localhost:8501
